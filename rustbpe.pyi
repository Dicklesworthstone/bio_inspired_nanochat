from typing import Iterable, Sequence, Tuple


class Tokenizer:
    def __init__(self) -> None: ...
    def train_from_iterator(
        self, iterator: Iterable[str], vocab_size: int, *, pattern: str | None = ...
    ) -> None: ...
    def get_pattern(self) -> str: ...
    def get_mergeable_ranks(self) -> Sequence[Tuple[bytes, int]]: ...
    def encode(self, text: str) -> list[int]: ...
    def decode(self, tokens: Sequence[int]) -> str: ...

